{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1KWp0l0wPVVdyOl1ffhc8SY6TOKkUXjxw",
      "authorship_tag": "ABX9TyOI2aQqaLqBRXKjBE89F86t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stefi96/DetectingNFTs-Master/blob/main/Images_NFTs_Master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "OR4v2ayYfrNW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to all the scam and legit images\n",
        "# NOTE: One option is the paths for google cloud and the other for running locally\n",
        "scam_image_paths = [os.path.join(\"/content/drive/MyDrive/Master/Project/Images/Images_scam\", image) for image in os.listdir(\"/content/drive/MyDrive/Master/Project/Images/Images_scam\")]\n",
        "legit_image_paths = [os.path.join(\"/content/drive/MyDrive/Master/Project/Images/Images_legit\", image) for image in os.listdir(\"/content/drive/MyDrive/Master/Project/Images/Images_legit\")]\n",
        "#scam_image_paths = [os.path.join(r\"C:\\Users\\stefanve\\Desktop\\Project\\Images\\Images_scam\", image) for image in os.listdir(r\"C:\\Users\\stefanve\\Desktop\\Project\\Images\\Images_scam\")]\n",
        "#legit_image_paths = [os.path.join(r\"C:\\Users\\stefanve\\Desktop\\Project\\Images\\Images_legit\", image) for image in os.listdir(r\"C:\\Users\\stefanve\\Desktop\\Project\\Images\\Images_legit\")]"
      ],
      "metadata": {
        "id": "YW4WzuAlhR9l"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Paths to your scam and legit images on Google Drive\n",
        "scam_dir = \"/content/drive/MyDrive/Master/Project/Images/Images_scam\"\n",
        "legit_dir = \"/content/drive/MyDrive/Master/Project/Images/Images_legit\"\n",
        "\n",
        "# List the images in the directories\n",
        "scam_images = os.listdir(scam_dir)\n",
        "legit_images = os.listdir(legit_dir)\n",
        "\n",
        "# Print the number of images detected in each directory\n",
        "print(f\"Number of scam images detected: {len(scam_images)}\")\n",
        "print(f\"Number of legit images detected: {len(legit_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cV51vGgixsO",
        "outputId": "e2279e60-374e-4e73-9510-2bee6d81f09a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of scam images detected: 1082\n",
            "Number of legit images detected: 1762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def try_loading_images(image_paths):\n",
        "    loaded_images = []\n",
        "    for img_path in image_paths[:10]:  # Limiting to the first 10 images for testing\n",
        "        try:\n",
        "            img = Image.open(img_path).resize((128, 128))\n",
        "            img_array = np.array(img) / 255.0\n",
        "            loaded_images.append(img_array)\n",
        "        except Exception as e:\n",
        "            print(f\"Error with image {img_path}: {e}\")\n",
        "    return loaded_images\n",
        "\n",
        "# Attempt to load and process a subset of scam and legit images\n",
        "loaded_scam_images = try_loading_images(scam_image_paths)\n",
        "loaded_legit_images = try_loading_images(legit_image_paths)\n",
        "\n",
        "print(f\"Number of scam images loaded: {len(loaded_scam_images)}\")\n",
        "print(f\"Number of legit images loaded: {len(loaded_legit_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyA-YvkQj4DT",
        "outputId": "c7d56184-4c28-4d46-d32b-f953c1efd4d8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of scam images loaded: 10\n",
            "Number of legit images loaded: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_images_modified(image_paths, label):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for img_path in image_paths:\n",
        "        try:\n",
        "            # Open the image and convert to RGB (removing any alpha channel)\n",
        "            img = Image.open(img_path).convert(\"RGB\").resize((128, 128))\n",
        "            img_array = np.array(img) / 255.0\n",
        "            data.append(img_array)\n",
        "            labels.append(label)\n",
        "        except Exception as e:\n",
        "            print(f\"Error with image {img_path}: {e}\")\n",
        "    return data, labels\n",
        "\n",
        "# Load and preprocess the images using the modified function\n",
        "scam_data, scam_labels = load_and_preprocess_images_modified(scam_image_paths, \"scam\")\n",
        "legit_data, legit_labels = load_and_preprocess_images_modified(legit_image_paths, \"legit\")\n",
        "\n",
        "# Combine data and labels\n",
        "all_data = scam_data + legit_data\n",
        "all_labels = scam_labels + legit_labels\n",
        "\n",
        "print(f\"Total number of images in all_data: {len(all_data)}\")\n",
        "print(f\"Total number of labels in all_labels: {len(all_labels)}\")"
      ],
      "metadata": {
        "id": "g4UDM4grniEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the debug function to load and preprocess images\n",
        "scam_data, scam_labels = load_and_preprocess_images_modified(scam_image_paths, \"scam\")\n",
        "legit_data, legit_labels = load_and_preprocess_images_modified(legit_image_paths, \"legit\")"
      ],
      "metadata": {
        "id": "NZfMjHIcqUqC"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = scam_data + legit_data\n",
        "all_labels = scam_labels + legit_labels\n",
        "\n",
        "print(f\"Total number of images in all_data: {len(all_data)}\")\n",
        "print(f\"Total number of labels in all_labels: {len(all_labels)}\")"
      ],
      "metadata": {
        "id": "NBIev345qV4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(all_data, all_labels, test_size=0.3, random_state=42, stratify=all_labels)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "print(f\"Training data size: {len(X_train)}\")\n",
        "print(f\"Validation data size: {len(X_val)}\")\n",
        "print(f\"Test data size: {len(X_test)}\")"
      ],
      "metadata": {
        "id": "DfPlTm9VqV1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_val = label_encoder.transform(y_val)\n",
        "y_test = label_encoder.transform(y_test)\n"
      ],
      "metadata": {
        "id": "FO8HN5qThgV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, 2)\n",
        "y_val = to_categorical(y_val, 2)\n",
        "y_test = to_categorical(y_test, 2)"
      ],
      "metadata": {
        "id": "RLSpLaqphgPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (128, 128, 3)\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Adding dropout layers\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "IGaRMoK8hgNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AeL1gRDpznpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "aLuD6UmPzo7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "TMT7q6FlzrjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)"
      ],
      "metadata": {
        "id": "cn6XJ2c10ViC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"y_val shape:\", y_val.shape)"
      ],
      "metadata": {
        "id": "cDxQhK2n0Wl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_epochs = 50  # Adjust this based on your requirements\n",
        "history = model.fit(datagen.flow(np.array(X_train), np.array(y_train), batch_size=32),\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=number_of_epochs,\n",
        "                    callbacks=[early_stop])\n",
        "#history = model.fit(np.array(X_train), np.array(y_train), epochs=10, batch_size=32, validation_data=(np.array(X_val), np.array(y_val)), callbacks=[early_stop])"
      ],
      "metadata": {
        "id": "vtNDA-LThgKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(np.array(X_test), np.array(y_test))\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "id": "GEYIFTrNhoWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original X_test shape: {np.array(X_test).shape}\")\n",
        "\n",
        "# Reshape if necessary\n",
        "X_test_reshaped = np.array(X_test).reshape(-1, 128, 128, 3)  # Assuming your images are 128x128 and RGB\n",
        "print(f\"Reshaped X_test shape: {X_test_reshaped.shape}\")"
      ],
      "metadata": {
        "id": "Ur2tnjR1hoSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Predict the labels for the test set using reshaped data\n",
        "y_pred = model.predict(X_test_reshaped)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Classification Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred_classes))\n",
        "\n",
        "# ROC-AUC\n",
        "# Note: This is for binary classification. If your task is multi-class, this will need adjustments.\n",
        "roc_auc = roc_auc_score(y_true, y_pred_classes)\n",
        "print(f\"\\nROC-AUC: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "Q3XCJC4bt2O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting training & validation accuracy\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "\n",
        "# Plotting training & validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FNNEiTNot3Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r7KduMrSt4aa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}