{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1KWp0l0wPVVdyOl1ffhc8SY6TOKkUXjxw",
      "authorship_tag": "ABX9TyPANMv2WUjLgmTP2k5BVnbr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stefi96/DetectingNFTs-Master/blob/main/Images_NFTs_Master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MOagqN4UhEh9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OR4v2ayYfrNW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess images\n",
        "def load_and_preprocess_images(image_paths, label):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for img_path in image_paths:\n",
        "        try:\n",
        "            img = Image.open(img_path).resize((128, 128))\n",
        "            img_array = np.array(img) / 255.0\n",
        "            data.append(img_array)\n",
        "            labels.append(label)\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    return data, labels\n"
      ],
      "metadata": {
        "id": "Cmm9lG6yfyDJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to all the scam and legit images\n",
        "# NOTE: Adjust these paths according to where you've stored the images in your Google Drive\n",
        "cam_image_paths = [os.path.join(\"/content/drive/MyDrive/Master/Project/Images/Images_scam\", image) for image in os.listdir(\"/content/drive/MyDrive/Master/Project/Images/Images_scam\")]\n",
        "egit_image_paths = [os.path.join(\"/content/drive/MyDrive/Master/Project/Images/Images_legit\", image) for image in os.listdir(\"/content/drive/MyDrive/Master/Project/Images/Images_legit\")]"
      ],
      "metadata": {
        "id": "YW4WzuAlhR9l"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Paths to your scam and legit images on Google Drive\n",
        "scam_dir = \"/content/drive/MyDrive/Master/Project/Images/Images_scam\"\n",
        "legit_dir = \"/content/drive/MyDrive/Master/Project/Images/Images_legit\"\n",
        "\n",
        "# List the images in the directories\n",
        "scam_images = os.listdir(scam_dir)\n",
        "legit_images = os.listdir(legit_dir)\n",
        "\n",
        "# Print the number of images detected in each directory\n",
        "print(f\"Number of scam images detected: {len(scam_images)}\")\n",
        "print(f\"Number of legit images detected: {len(legit_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cV51vGgixsO",
        "outputId": "7e002912-301c-4d92-ec96-7da74b2e1af1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of scam images detected: 1082\n",
            "Number of legit images detected: 1763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def try_loading_images(image_paths):\n",
        "    loaded_images = []\n",
        "    for img_path in image_paths[:10]:  # Limiting to the first 10 images for testing\n",
        "        try:\n",
        "            img = Image.open(img_path).resize((128, 128))\n",
        "            img_array = np.array(img) / 255.0\n",
        "            loaded_images.append(img_array)\n",
        "        except Exception as e:\n",
        "            print(f\"Error with image {img_path}: {e}\")\n",
        "    return loaded_images\n",
        "\n",
        "# Attempt to load and process a subset of scam and legit images\n",
        "loaded_scam_images = try_loading_images(scam_image_paths)\n",
        "loaded_legit_images = try_loading_images(legit_image_paths)\n",
        "\n",
        "print(f\"Number of scam images loaded: {len(loaded_scam_images)}\")\n",
        "print(f\"Number of legit images loaded: {len(loaded_legit_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyA-YvkQj4DT",
        "outputId": "4fe1831a-96a4-4fd9-d086-e44608709b36"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of scam images loaded: 10\n",
            "Number of legit images loaded: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scam_data, scam_labels = load_and_preprocess_images(scam_images, \"scam\")\n",
        "legit_data, legit_labels = load_and_preprocess_images(legit_images, \"legit\")\n",
        "\n",
        "all_data = scam_data + legit_data\n",
        "all_labels = scam_labels + legit_labels"
      ],
      "metadata": {
        "id": "TRKe56CLg2Uq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading all scam images\n",
        "scam_data, scam_labels = load_and_preprocess_images(scam_image_paths, \"scam\")\n",
        "\n",
        "# Loading all legit images\n",
        "legit_data, legit_labels = load_and_preprocess_images(legit_image_paths, \"legit\")\n",
        "\n",
        "# Printing the number of loaded images and labels\n",
        "print(f\"Number of scam images loaded: {len(scam_data)}\")\n",
        "print(f\"Number of legit images loaded: {len(legit_data)}\")"
      ],
      "metadata": {
        "id": "LrMaiMX_kaqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(all_data, all_labels, test_size=0.3, random_state=42, stratify=all_labels)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "_loUUE9lhatD",
        "outputId": "48b8378d-1b81-4a9a-d8cc-7d3a5666f5f1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d996978472a5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2563\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2237\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_val = label_encoder.transform(y_val)\n",
        "y_test = label_encoder.transform(y_test)\n"
      ],
      "metadata": {
        "id": "FO8HN5qThgV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, 2)\n",
        "y_val = to_categorical(y_val, 2)\n",
        "y_test = to_categorical(y_test, 2)"
      ],
      "metadata": {
        "id": "RLSpLaqphgPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "IGaRMoK8hgNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(np.array(X_train), np.array(y_train), epochs=10, batch_size=32, validation_data=(np.array(X_val), np.array(y_val)))"
      ],
      "metadata": {
        "id": "vtNDA-LThgKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(np.array(X_test), np.array(y_test))\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "id": "GEYIFTrNhoWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ur2tnjR1hoSL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}